{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "##### Part 0: housekeeping \n",
    "import csv\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_col(dataframe, col_to_move, reference_col, right=True):\n",
    "    col_list = dataframe.columns.values.tolist()\n",
    "    col_list2 = [x for x in col_list if x != col_to_move]\n",
    "    reference_idx = col_list2.index(reference_col)\n",
    "    if right==True:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.append(col_to_move)\n",
    "        return dataframe[col_list3]\n",
    "    else:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.insert(-2, col_to_move)\n",
    "        return  dataframe[col_list3]\n",
    "\n",
    "def PopSamples(pool, num_subset):\n",
    "    np.random.shuffle(pool)\n",
    "    return pool[:num_subset]\n",
    "\n",
    "def ttest_is_significant (series1, series2, threshold=0.05, equal_var=False):\n",
    "    #statistic = stats.ttest_ind(series1, series2, equal_var=equal_var).statistic\n",
    "    #pvalue = stats.ttest_ind(series1, series2, equal_var=equal_var).pvalue\n",
    "    ret = stats.ttest_ind(series1, series2, equal_var=equal_var)\n",
    "    if ret.pvalue > threshold: \n",
    "        result = 1  # pass, i.e, 'Insignificant'\n",
    "    else:\n",
    "        result = 0  # fail, i.e, 'Significantly different distribution'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "I_Mean_RT_m = 784.10\n",
    "I_Mean_RT_sd = 134.98\n",
    "I_Mean_Acc_m = 0.84\n",
    "I_Mean_Acc_sd = 0.20\n",
    "AgeOfAcqsn_m = 9.71\n",
    "AgeOfAcsqn_sd = 2.96\n",
    "LogFreqHAL_m = 6.16\n",
    "LogFreqHAL_sd = 2.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_init: 403   **before cleaning**\n",
      "df_init:  403  **after cleaning**\n",
      "df_in:  384\n",
      "df_synmatch:  188\n",
      "df_semmatch:  84\n"
     ]
    }
   ],
   "source": [
    "starting_list = '/Users/songheekim/Google Drive/Primary/Projects/VerbVector/final_list/50_55_55_candidate1_wb.csv'\n",
    "df_raw = pd.read_csv(starting_list, index_col='Lemma')\n",
    "df_init = pd.read_csv(starting_list, index_col='Lemma')\n",
    "print('df_init:', df_init.shape[0], '  **before cleaning**')\n",
    "\n",
    "### z-scoring\n",
    "df_init['I_Mean_RT_z'] = (df_init['I_Mean_RT']-I_Mean_RT_m)/I_Mean_RT_sd\n",
    "df_init['I_Mean_Accuracy_z'] = (df_init['I_Mean_Accuracy']-I_Mean_Acc_m)/I_Mean_Acc_sd\n",
    "df_init['AgeofAcqsn_z'] = (df_init['AgeofAcqsn']-AgeOfAcqsn_m)/AgeOfAcsqn_sd\n",
    "df_init['LogFreqHAL_z'] = (df_init['LogFreqHAL']-LogFreqHAL_m)/LogFreqHAL_sd\n",
    "\n",
    "#df_init = df_init.loc[df_init['badverb']=='n'] ## subset so that df_init only includes 'good' verbs\n",
    "df_in = df_init.loc[df_init['in']==1] ### in==0: potentially ambiguous verbs\n",
    "df_synmatch = df_in.loc[df_in['syn_matched']==1]\n",
    "df_semmatch = df_in.loc[df_in['sem_matched']==1]\n",
    "sem_tab = pd.crosstab(df_in.SemClass, df_in.SynClass, margins=True).sort_values(by='All', ascending=False)\n",
    "\n",
    "print ('df_init: ', df_init.shape[0], ' **after cleaning**')\n",
    "print ('df_in: ', df_in.shape[0])\n",
    "print ('df_synmatch: ', df_synmatch.shape[0])\n",
    "print ('df_semmatch: ', df_semmatch.shape[0])\n",
    "\n",
    "#z=1.282 ##90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init: 403   **before cleaning**\n",
    "df_init:  388  **after cleaning**\n",
    "df_in:  384\n",
    "df_synmatch:  188\n",
    "df_semmatch:  84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### let's mark some marginal ones. \n",
    "### Part1: based on absolute criteria (ELP statistics)\n",
    "# marginal = {}\n",
    "# criteria = ['I_Mean_RT_z','I_Mean_Accuracy_z', 'AgeofAcqsn_z', 'LogFreqHAL_z']\n",
    "# for c in criteria: \n",
    "#     marginal[c] = dict.fromkeys(['high10', 'low10'])\n",
    "#     #print ('==========', c, '=========')\n",
    "#     #print ('lowest 10%', df_init.loc[df_init[c] <= -1.282].index.tolist())\n",
    "#     marginal[c]['low10'] = df_init.loc[df_init[c] <= -1.282].index.tolist()\n",
    "#     #print ('highest 10%', df_init.loc[df_init[c] >= 1.282].index.tolist())\n",
    "#     marginal[c]['high10'] = df_init.loc[df_init[c] >= 1.282].index.tolist()\n",
    "\n",
    "# 'disintegrate' in marginal['LogFreqHAL_z']['low10']\n",
    "\n",
    "#import scipy.stats as st\n",
    "#st.norm.ppf(0.999) ## from percentile to z score\n",
    "# st.norm.cdf(1) ## from z score to percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_percentile(zscore, polarity): \n",
    "    '''function that take in Z score, return: \n",
    "       the proportion of data larger than the z-score (if polarity='upper')\n",
    "       the proportion of data smaller than the z-score (if polarity='lower')'''\n",
    "    import scipy.stats as st\n",
    "    if polarity == 'upper':\n",
    "        absolute_percentile = 1 - st.norm.cdf(zscore)\n",
    "    elif polarity == 'lower':\n",
    "        absolute_percentile = st.norm.cdf(zscore)\n",
    "    else:\n",
    "        raise Exception('Polarity should be either \\'upper\\' or \\'lower\\'')\n",
    "    return round(absolute_percentile,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensue 1\n",
      "ensue 0\n",
      "recur 1\n",
      "recur 0\n",
      "seep 1\n",
      "seep 0\n",
      "swerve 1\n",
      "swerve 0\n",
      "writhe 1\n",
      "writhe 0\n"
     ]
    }
   ],
   "source": [
    "#### let's find some marginal ones. \n",
    "############### PART1: based on absolute criteria (ELP statistics)##########\n",
    "df_init_dict = df_init.to_dict(orient='index')\n",
    "# print ('before==============')\n",
    "# print (df_init_dict['writhe'], '\\n')\n",
    "\n",
    "###### create a metric, i.e.,'absolute marginality' \n",
    "import scipy.stats as st\n",
    "for k, v in df_init_dict.items():\n",
    "    if v['I_Mean_Accuracy_z'] <= st.norm.ppf(0.2): \n",
    "        #print (k, 'will be dropped')\n",
    "        v['abs_marginality'] = 0   ### Mark it marginal if LD MeanAccuracy is below 20% cutoff\n",
    "    else:\n",
    "        rt_marginal = get_absolute_percentile(v['I_Mean_RT_z'], 'upper') #how extremely HIGH the RT is\n",
    "        acc_marginal = get_absolute_percentile(v['I_Mean_Accuracy_z'], 'lower') #how extremely LOW the accuracy is\n",
    "        acqsn_marginal = get_absolute_percentile(v['AgeofAcqsn_z'], 'upper') \n",
    "        freq_marginal = get_absolute_percentile(v['LogFreqHAL_z'], 'lower')\n",
    "        v['abs_marginality'] = round((rt_marginal + acc_marginal + acqsn_marginal + freq_marginal)/4, 4)\n",
    "\n",
    "# print ('absolute added==============')\n",
    "# print (df_init_dict['writhe'], '\\n')\n",
    "\n",
    "################ PART2: based on relative ranking of marginality\n",
    "\n",
    "#df_init['I_Mean_RT'].sort_values(ascending=False)[:38] ###member with largest 10% RT \n",
    "#df_init['I_Mean_Accuracy'].sort_values(ascending=True)[:38] ### members with lowest 10% Accuracy \n",
    "#df_init['AgeofAcqsn'].sort_values(ascending=False)[:38] ### member with highest 10% Age of Acquisition\n",
    "#df_init['LogFreqHAL'].sort_values(ascending=True)[:38] ### members with lowest 10% LogFreqHAL\n",
    "rt_rel_marginal = df_init['I_Mean_RT'].sort_values(ascending=False)[:38].index.tolist()\n",
    "accuracy_rel_marginal = df_init['I_Mean_Accuracy'].sort_values(ascending=True)[:38].index.tolist()\n",
    "ageofacqsn_rel_marginal = df_init['AgeofAcqsn'].sort_values(ascending=False)[:38].index.tolist()\n",
    "logfreqhal_rel_marginal = df_init['LogFreqHAL'].sort_values(ascending=True)[:38].index.tolist()\n",
    "\n",
    "rt_accuracy = [i for i in accuracy_rel_marginal if i in rt_rel_marginal] \n",
    "rt_accuracy_freq = [i for i in logfreqhal_rel_marginal if i in rt_accuracy]\n",
    "rt_accuracy_freq_age = [i for i in logfreqhal_rel_marginal if i in rt_accuracy_freq]\n",
    "marginal_relative = sorted(rt_accuracy_freq_age)\n",
    "\n",
    "for k, v in df_init_dict.items():\n",
    "    if k in marginal_relative: \n",
    "        v['rel_marginality'] = 'y'   ### Mark it marginal if found in marginal_relative list\n",
    "    else:\n",
    "        v['rel_marginality'] = 'n'\n",
    "        \n",
    "# print ('relative added==============')\n",
    "# print (df_init_dict['writhe'], '\\n')\n",
    "\n",
    "### convert the dict to a df and save\n",
    "df_init_updated = pd.DataFrame.from_dict(df_init_dict, orient='index')\n",
    "\n",
    "### find what's common between relative and absolute \n",
    "marginal_absolute = df_init_updated.sort_values(by='abs_marginality')[:20].index.tolist()\n",
    "#print ('marginal_absolute', marginal_absolute)\n",
    "marginal_absolute_relative = [i for i in marginal_relative if i in marginal_absolute]\n",
    "#print ('marginal by any criterion:', marginal_absolute_relative)\n",
    "\n",
    "\n",
    "#### exclude verbs that are marginal by either criterion\n",
    "for verb in marginal_absolute_relative: \n",
    "    print (verb, df_init_updated.loc[verb, 'in'])\n",
    "    df_init_updated.loc[verb, 'in'] = 0\n",
    "    print (verb, df_init_updated.loc[verb, 'in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_out = df_init_updated.sort_values(by=['badverb', 'in', 'syn_matched', 'SynClass', 'GrandIndex'], ascending=[True, False, False, False, True])\n",
    "df_out.to_csv('/Users/songheekim/Google Drive/Primary/Projects/VerbVector/Verblists/List300_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_absolute_percentile(-1.645, 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### draw venn diagram\n",
    "# \n",
    "# musicians = {from venn import venn\n",
    "# rel_marginal = {\n",
    "#     'RT': set(rt_rel_marginal),\n",
    "#     'Accuaracy' : set(accuracy_rel_marginal), \n",
    "#     'AgeOfAcqsn': set(ageofacqsn_rel_marginal), \n",
    "#     'LogFreqHAL': set(logfreqhal_rel_marginal)\n",
    "# }\n",
    "#     \"Members of The Beatles\": {\"Paul McCartney\", \"John Lennon\", \"George Harrison\", \"Ringo Starr\"},\n",
    "#     \"Guitarists\": {\"John Lennon\", \"George Harrison\", \"Jimi Hendrix\", \"Eric Clapton\", \"Carlos Santana\"},\n",
    "#     \"Played at Woodstock\": {\"Jimi Hendrix\", \"Carlos Santana\", \"Keith Moon\"}\n",
    "# }\n",
    "venn(rel_marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ages = [5, 12, 17, 18, 24, 32]\n",
    "\n",
    "# def myFunc(x):\n",
    "#     if x < 18:\n",
    "#         return False\n",
    "#     else:\n",
    "#         return True\n",
    "\n",
    "# adults = filter(myFunc, ages)\n",
    "\n",
    "# for a in adults:\n",
    "#     print(a)\n",
    "\n",
    "# aa=5\n",
    "#globals()['aa'] + 10\n",
    "#locals().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_updated = pd.DataFrame.from_dict(df_init_dict, orient='index')\n",
    "df_dict_updated_sort = df_dict_updated.sort_values(by='marginality', ascending=True)\n",
    "marginal_absolute = sorted(df_dict_updated_sort[:10].index.tolist())\n",
    "# for k, v in df_init_dict.items():\n",
    "#     print (k, v['marginality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ CHECK IF SYNTACTIC CATEGORIES ARE MATCHED FOR LOW LEVEL QUALITIES \n",
    "syncat = ['unergative', 'unaccusative', 'transitive']\n",
    "print ('df_synmatch:', df_synmatch.shape)\n",
    "\n",
    "unergative = df_synmatch.loc[df_synmatch['SynClass']=='unergative']\n",
    "unaccusative = df_synmatch.loc[df_synmatch['SynClass']=='unaccusative']\n",
    "transitive = df_synmatch.loc[df_synmatch['SynClass']=='transitive']\n",
    "\n",
    "print ('unergative:', unergative.shape[0])\n",
    "print ('unaccusative:', unaccusative.shape[0])\n",
    "print ('transitive:', transitive.shape[0])\n",
    "\n",
    "cols_test = ['LogFreqHAL', 'AgeofAcqsn', 'Length', 'Ortho_N', 'Phono_N', 'OLD', 'PLD', 'NPhon', 'NSyll', \\\n",
    "            'I_Mean_RT', 'I_Mean_Accuracy', 'I_NMG_Mean_RT', 'I_NMG_Mean_Accuracy', 'N2_F', 'N3_F']\n",
    "pairs1 = [('unergative', 'unaccusative'), ('unaccusative', 'transitive'), ('transitive', 'unergative')]\n",
    "\n",
    "for c in cols_test:\n",
    "    print ('===========', c, '============')\n",
    "    for p in pairs1:\n",
    "        x = ttest_is_significant(df_synmatch.loc[df_synmatch['SynClass']==p[0]][c].tolist(), \\\n",
    "                         df_synmatch.loc[df_synmatch['SynClass']==p[1]][c].tolist(), \\\n",
    "                         threshold=0.05, equal_var=False)\n",
    "        if x == 0:\n",
    "            print (c, p, 'p < 0.05')\n",
    "            print ('-->', p[0], round(df_synmatch.loc[df_synmatch['SynClass']==p[0]][c].mean(),2))\n",
    "            print ('-->', p[1], round(df_synmatch.loc[df_synmatch['SynClass']==p[1]][c].mean(),2))\n",
    "print ('syntactic test finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'live' in unergative.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### metric: AgeofAcqsn, LogFreqHAL, I_Mean_RT, I_Mean_Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
